{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"modeling\": {\n",
    "        \"dummy\": True,\n",
    "        \"linear_reg\": True,\n",
    "        \"svr\": True,\n",
    "        \"tree\": True,\n",
    "        \"forest\": True,\n",
    "        \"xgboost\": True\n",
    "    },\n",
    "    \"explain\": {\n",
    "        \"setup\": False,\n",
    "        \"bar\": False,\n",
    "        \"force\": False,\n",
    "        \"waterfall\": False,\n",
    "        \"summary\": False,\n",
    "        \"dependence\": False\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 1 Dependency import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler, minmax_scale\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import set_config\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "plt.style.use([\"default\"])\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical_features_name(dataset, split_by_unique_count=True, split_count=10):\n",
    "    features_name = dataset.select_dtypes([\"object\", \"bool\"]).columns\n",
    "    if split_by_unique_count:\n",
    "        less_uniques = [feature_name for feature_name in features_name if dataset[feature_name].nunique() <= split_count]\n",
    "        lot_uniques = features_name.difference(less_uniques).tolist()\n",
    "        return (less_uniques, lot_uniques)\n",
    "    else:\n",
    "        return features_name.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numerical_features_name(dataset):\n",
    "    features_name = dataset.select_dtypes([\"int64\", \"float64\"]).columns.values.tolist()\n",
    "    return features_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationResult():\n",
    "    def __init__(self, gridsearch, target, X_train, y_train, X_test, y_test, num_cols, cat_less_unique_cols, cat_lot_unique_cols):\n",
    "        self.__gs = gridsearch\n",
    "        self.__X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.__X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.__target = target\n",
    "        self.__score = self.__gs.score(self.__X_test, self.y_test)\n",
    "        self.__ratio = np.abs((self.__score * 100) / self.y_test.mean())\n",
    "        self.__num_cols = num_cols\n",
    "        self.__cat_less_unique_cols = cat_less_unique_cols\n",
    "        self.__cat_lot_unique_cols = cat_lot_unique_cols\n",
    "        self.__cat_less_unique_cols_preproc = self.__gs.best_estimator_[\"transforms\"].transformers_[1][1][\"one_hot_encoder\"].get_feature_names_out(self.__cat_less_unique_cols).tolist()\n",
    "\n",
    "        self.best_model = self.__gs.best_estimator_.named_steps[\"model\"]\n",
    "        self.feature_names = self.__num_cols + self.__cat_less_unique_cols_preproc + self.__cat_lot_unique_cols\n",
    "\n",
    "        self.X_train_transform = pd.DataFrame(data=self.__gs.best_estimator_.named_steps[\"transforms\"].transform(self.__X_train), columns=self.feature_names)\n",
    "        self.X_test_transform = pd.DataFrame(data=self.__gs.best_estimator_.named_steps[\"transforms\"].transform(self.__X_test), columns=self.feature_names)\n",
    "\n",
    "    def print_metrics(self):\n",
    "        print(f\"RMSE: {-self.__score:.4}\")\n",
    "        print(f\"Target mean value: {self.__target.mean():.4}\")\n",
    "        print(f\"Ratio: {self.__ratio:.4}%\")\n",
    "        print(f\"best_params: {self.__gs.best_params_}\")\n",
    "\n",
    "    def print_feature_importance(self, show_raw=True):\n",
    "        fi = pd.Series(self.best_model.feature_importances_, index=self.feature_names).sort_values(ascending=False)\n",
    "\n",
    "        fi.plot.bar(figsize=(20, 3))\n",
    "\n",
    "        plt.title(\"Feature importances using MDI\", size=20)\n",
    "        plt.ylabel(\"Mean decrease in impurity\", size=16)\n",
    "        plt.xticks(rotation=45, size=16, ha=\"right\")\n",
    "        plt.yticks(size=16)\n",
    "        plt.show()\n",
    "\n",
    "        if show_raw:\n",
    "            print(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, grid_params, dataset, target, scoring=\"neg_root_mean_squared_error\"):\n",
    "    set_config(display=\"diagram\") # display=\"text\" -> for textual output\n",
    "\n",
    "    ### DATASET PREPARATION ###\n",
    "\n",
    "    y = dataset[target].copy()\n",
    "    X = dataset.drop(columns=[target]).copy()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=1)\n",
    "\n",
    "    categorical_cols_less_unique, categorical_cols_lot_unique = get_categorical_features_name(X_train)\n",
    "    numerical_cols = get_numerical_features_name(X_train)\n",
    "\n",
    "    ### PIPELINE CONSTRUCTION ###\n",
    "\n",
    "    num_pipe = Pipeline(steps=[\n",
    "        (\"simple_imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    ])\n",
    "\n",
    "    cat_less_unique_pipe = Pipeline(steps=[\n",
    "        (\"simple_imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    cat_lot_unique_pipe = Pipeline(steps=[\n",
    "        (\"simple_imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"ordinal_encoder\", OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan)),\n",
    "        (\"simple_imputer_bis\", SimpleImputer(strategy=\"mean\")),\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num_pipe\", num_pipe, numerical_cols),\n",
    "        (\"cat_less_unique_pipe\", cat_less_unique_pipe, categorical_cols_less_unique),\n",
    "        (\"cat_lot_unique_pipe\", cat_lot_unique_pipe, categorical_cols_lot_unique)\n",
    "    ])\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        (\"transforms\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    ### GRIDSEARCH DECLARATION AND FITTING ###\n",
    "\n",
    "    gs = GridSearchCV(pipeline, grid_params, scoring=scoring, refit=True)\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    return EvaluationResult(gs, y, X_train, y_train, X_test, y_test, numerical_cols, categorical_cols_less_unique, categorical_cols_lot_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mi_scores(X, y, discrete_features):\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores)\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(\"Mutual Information Scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 2 Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/data-cleaned.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_1 = \"SiteEnergyUse(kBtu)\"\n",
    "target_2 = \"GHGEmissionsIntensity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[target_2], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"DefaultData\"] = data[\"DefaultData\"].astype(\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.drop(columns=[\"ThirdLargestPropertyUseType\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 3 Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 3.2 ListOfAllPropertyUseTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = \"ListOfAllPropertyUseTypes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_elt_in_list(row):\n",
    "    if type(row) == float:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(row.split(\",\"))\n",
    "\n",
    "new_feature = \"Count_\" + feature\n",
    "\n",
    "data[new_feature] = data.apply(lambda row: nb_elt_in_list(row[feature]), axis=1)\n",
    "data[[feature, new_feature]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[feature], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 3.3 Address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe the address incorporate informations that can be usefull for the model if it can be decomposed:\n",
    "- number of building (405, 1619 ...)\n",
    "- stress name (olive, 5th, fourth ...)\n",
    "- kind of way (way, street, avenue, st ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = \"Address\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[feature].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[feature].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[feature].replace(to_replace=\"[-.&]|( s )|( e )|( n )|( ne )|( sw )|( st)|( nw )|( w )\", value=\"\", regex=True, inplace=True)\n",
    "new_df = data[feature].str.split(expand=True).rename(columns={0: \"BuildingNumber\", 1: \"WayName\", 2: \"WayKind\"}).iloc[:, :3]\n",
    "new_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[\"BuildingNumber\"] = pd.to_numeric(new_df[\"BuildingNumber\"], errors=\"coerce\", downcast=\"integer\")\n",
    "new_df[\"BuildingNumber\"] = new_df[\"BuildingNumber\"].replace(np.nan, new_df[\"BuildingNumber\"].mean())\n",
    "new_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[\"BuildingNumber\"] = minmax_scale(new_df[\"BuildingNumber\"], feature_range=(1, 100))\n",
    "new_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.join([new_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[feature], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 3.4 Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[target_1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[target_1] < 1e5][target_1].count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[target_1].replace(0, data[target_1].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[target_1].hist(bins=100)\n",
    "plt.title(target_1 + \" distribution\")\n",
    "plt.xlabel(\"Energy (kBtu)\")\n",
    "plt.ylabel(\"Occurence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[target_1] = np.log(data[target_1])\n",
    "data[target_1].hist(bins=100)\n",
    "plt.title(target_1 + \"_log distribution\")\n",
    "plt.xlabel(\"Energy (kBtu)\")\n",
    "plt.ylabel(\"Occurence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 4 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"modeling\"][\"dummy\"]:\n",
    "\n",
    "    model = DummyRegressor()\n",
    "\n",
    "    grid_params = [\n",
    "        {\n",
    "            \"model__strategy\": [\"mean\", \"median\"]\n",
    "        },\n",
    "        {\n",
    "            \"model__strategy\": [\"quantile\"],\n",
    "            \"model__quantile\": np.arange(0, 1.1, 0.1),\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    eval_result = evaluate(model, grid_params, data, target_1)\n",
    "\n",
    "    eval_result.print_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.2 LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"modeling\"][\"linear_reg\"]:\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "    grid_params = [\n",
    "        {\n",
    "            \"model__fit_intercept\": [True]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    eval_result = evaluate(model, grid_params, data, target_1)\n",
    "\n",
    "    eval_result.print_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.3 SupportVectorRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"modeling\"][\"svr\"]:\n",
    "\n",
    "    model = SVR()\n",
    "\n",
    "    grid_params = [\n",
    "        {\n",
    "            \"model__kernel\": [\"rbf\"],\n",
    "            \"model__degree\": [3],\n",
    "            \"model__gamma\": [\"scale\"]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    eval_result = evaluate(model, grid_params, data, target_1)\n",
    "\n",
    "    eval_result.print_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.4 DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"modeling\"][\"tree\"]:\n",
    "\n",
    "    model = DecisionTreeRegressor()\n",
    "\n",
    "    grid_params = [\n",
    "        {\n",
    "            \"model__random_state\": [1],\n",
    "            \"model__max_depth\": [2, 3, 4],\n",
    "            \"model__min_samples_leaf\": range(1, 11, 1),\n",
    "            \"model__criterion\": [\"squared_error\"]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    eval_result = evaluate(model, grid_params, data, target_1)\n",
    "\n",
    "    eval_result.print_metrics()\n",
    "    eval_result.print_feature_importance(show_raw=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.5 RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"modeling\"][\"forest\"]:\n",
    "\n",
    "    model = RandomForestRegressor()\n",
    "\n",
    "    grid_params = [\n",
    "        {\n",
    "            \"model__random_state\": [1],\n",
    "            \"model__n_estimators\": [25],\n",
    "            \"model__min_samples_leaf\": [1],\n",
    "            \"model__criterion\": [\"squared_error\"]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    eval_result = evaluate(model, grid_params, data, target_1)\n",
    "\n",
    "    eval_result.print_metrics()\n",
    "    eval_result.print_feature_importance(show_raw=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.6 XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"modeling\"][\"xgboost\"]:\n",
    "\n",
    "    model = XGBRegressor()\n",
    "\n",
    "    grid_params = [\n",
    "        {\n",
    "            \"model__random_state\": [1],\n",
    "            \"model__max_depth\": [6], # 6, 3 .. 10\n",
    "            \"model__n_estimators\": [100], # 100, 100 .. 1000\n",
    "            \"model__learning_rate\": [0.04], # 0.3, 0.01 .. 0.3\n",
    "            \"model__colsample_bytree\": [1], # 1, 0.5 .. 1\n",
    "            \"model__subsample\": [1], # 1, 0.6 .. 1\n",
    "            \"model__alpha\": [0], # 0\n",
    "            \"model__lambda\": [1], # 1\n",
    "            \"model__gamma\": [0], # 0\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    eval_result = evaluate(model, grid_params, data, target_1)\n",
    "\n",
    "    eval_result.print_metrics()\n",
    "    eval_result.print_feature_importance(show_raw=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 5 Feature explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Explainer setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"setup\"]:\n",
    "    explainer = shap.TreeExplainer(eval_result.best_model, data=eval_result.X_train_transform)\n",
    "    explainer_bis = explainer(eval_result.X_train_transform)\n",
    "    shap_values = explainer.shap_values(eval_result.X_train_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 5.2 SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"bar\"]:\n",
    "    shap.plots.bar(explainer_bis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"force\"]:\n",
    "    shap.force_plot(explainer.expected_value, shap_values[0,:], eval_result.X_train_transform.iloc[0,:], matplotlib=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"waterfall\"]:\n",
    "    shap.plots.waterfall(explainer_bis[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 5.3 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"summary\"]:\n",
    "    shap.summary_plot(shap_values, eval_result.X_train_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 5.4 Dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"dependence\"]:\n",
    "    shap.decision_plot(explainer.expected_value, shap_values, features=eval_result.X_train_transform, feature_names=eval_result.feature_names, ignore_warnings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"dependence\"]:\n",
    "    shap.dependence_plot(\"PrimaryPropertyType\", shap_values, eval_result.X_train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"dependence\"]:\n",
    "    shap.dependence_plot(\"BuildingType_multifamily lr (1-4)\", shap_values, eval_result.X_train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"dependence\"]:\n",
    "    shap.dependence_plot(\"LargestPropertyUseType\", shap_values, eval_result.X_train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"dependence\"]:\n",
    "    shap.dependence_plot(\"Count_ListOfAllPropertyUseTypes\", shap_values, eval_result.X_train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"dependence\"]:\n",
    "    shap.dependence_plot(\"BuildingNumber\", shap_values, eval_result.X_train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"dependence\"]:\n",
    "    shap.dependence_plot(\"PropertyName\", shap_values, eval_result.X_train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"dependence\"]:\n",
    "    shap.dependence_plot(\"TaxParcelIdentificationNumber\", shap_values, eval_result.X_train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"dependence\"]:\n",
    "    shap.dependence_plot(\"Latitude\", shap_values, eval_result.X_train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"dependence\"]:\n",
    "    shap.dependence_plot(\"Longitude\", shap_values, eval_result.X_train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"dependence\"]:\n",
    "    shap.dependence_plot(\"WayName\", shap_values, eval_result.X_train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"dependence\"]:\n",
    "    shap.dependence_plot(\"ENERGYSTARScore\", shap_values, eval_result.X_train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"dependence\"]:\n",
    "    shap.dependence_plot(\"Neighborhood\", shap_values, eval_result.X_train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"dependence\"]:\n",
    "    shap.dependence_plot(\"NumberofFloors\", shap_values, eval_result.X_train_transform)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "586ad1ed5c97141e2437e681efbf1ec0adcd17d830cf5af2ca3d2819e743e158"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
