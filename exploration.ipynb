{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1368,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"feature_eng\": {\n",
    "\n",
    "    },\n",
    "    \"modeling\": {\n",
    "        \"dummy\": False,\n",
    "        \"linear_reg\": False,\n",
    "        \"svr\": False,\n",
    "        \"tree\": False,\n",
    "        \"forest\": False,\n",
    "        \"xgboost\": True\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 1 Dependency import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1369,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import set_config\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, grid_params, scoring=\"neg_root_mean_squared_error\"):\n",
    "    set_config(display=\"diagram\")\n",
    "    # set_config(display=\"text\")\n",
    "\n",
    "    num_pipe = Pipeline(steps=[\n",
    "        (\"simple_imputer\", SimpleImputer(strategy=\"mean\"))\n",
    "    ])\n",
    "\n",
    "    cat_less_unique_pipe = Pipeline(steps=[\n",
    "        (\"simple_imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    cat_lot_unique_pipe = Pipeline(steps=[\n",
    "        (\"simple_imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num_pipe\", num_pipe, numerical_cols),\n",
    "        (\"cat_less_unique_pipe\", cat_less_unique_pipe, categorical_cols_less_unique),\n",
    "        (\"cat_lot_unique_pipe\", cat_lot_unique_pipe, categorical_cols_lot_unique)\n",
    "    ])\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        (\"transforms\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    gs = GridSearchCV(pipeline, grid_params, scoring=scoring).fit(X_train, y_train)\n",
    "\n",
    "    score = gs.score(X_test, y_test)\n",
    "    ratio = (score * 100) / y_test.mean()\n",
    "    ratio = np.abs(ratio)\n",
    "\n",
    "    return score, ratio, gs, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1371,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mi_scores(X, y, discrete_features):\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores)\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(\"Mutual Information Scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 2 Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1373,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/data-cleaned.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1374,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target = \"GHGEmissionsIntensity(kgCO2e/ft2)\"\n",
    "target = \"SiteEnergyUse(kBtu)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1375,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[target]\n",
    "X = data.drop(columns=[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1376,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test_full, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1377,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols_less_unique = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and X_train_full[cname].dtype == \"object\"]\n",
    "categorical_cols_lot_unique = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() >= 10 and X_train_full[cname].dtype == \"object\"]\n",
    "numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1378,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cols = categorical_cols_lot_unique + categorical_cols_less_unique + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_test = X_test_full[my_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    651.000000\n",
       "mean       0.059682\n",
       "std        1.036777\n",
       "min       -1.765320\n",
       "25%       -0.837024\n",
       "50%       -0.141208\n",
       "75%        0.950418\n",
       "max        2.070824\n",
       "Name: SiteEnergyUse(kBtu), dtype: float64"
      ]
     },
     "execution_count": 1379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 3 Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1380,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_MI = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1381,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_MI[\"DefaultData\"] = X_MI[\"DefaultData\"].astype(\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1382,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_MI_NUM = X_MI.select_dtypes([\"int64\", \"float64\"]).columns\n",
    "X_MI_CAT = X_MI.select_dtypes([\"object\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1383,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_features = X_MI.dtypes == object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impt_num = SimpleImputer(strategy=\"mean\")\n",
    "# X_MI[X_MI_NUM] = pd.DataFrame(impt_num.fit_transform(X_MI[X_MI_NUM]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impt_cat = SimpleImputer(strategy=\"most_frequent\")\n",
    "# X_MI[X_MI_CAT] = pd.DataFrame(impt_cat.fit_transform(X_MI[X_MI_CAT]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in X_MI_CAT:\n",
    "#     X_MI[col], _ = X_MI[col].factorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = make_mi_scores(X_MI, y, discrete_features).sort_values(ascending=False)\n",
    "# scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_mi_scores(scores):\n",
    "#     plt.figure(dpi=100, figsize=(8, 5))\n",
    "#     scores = scores.sort_values(ascending=True)\n",
    "#     width = np.arange(len(scores))\n",
    "#     ticks = list(scores.index)\n",
    "#     plt.barh(width, scores)\n",
    "#     plt.yticks(width, ticks)\n",
    "#     plt.title(\"Mutual Information Scores\")\n",
    "\n",
    "# plot_mi_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 4 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.1 DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 7.39 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if config[\"modeling\"][\"dummy\"]:\n",
    "\n",
    "    model = DummyRegressor()\n",
    "\n",
    "    grid_params = [\n",
    "        {\n",
    "            \"model__strategy\": [\"mean\", \"median\"]\n",
    "        },\n",
    "        {\n",
    "            \"model__strategy\": [\"quantile\"],\n",
    "            \"model__quantile\": np.arange(0, 1.1, 0.1),\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    score, ratio, gs, pipeline = evaluate(model, grid_params)\n",
    "\n",
    "    print(f\"RMSE: {score:n} / RATIO: {ratio:.4}%\")\n",
    "    print(f\"best_params: {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.2 LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 8.82 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if config[\"modeling\"][\"linear_reg\"]:\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "    grid_params = [\n",
    "        {\n",
    "            \"model__fit_intercept\": [True]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    score, ratio, gs, pipeline = evaluate(model, grid_params)\n",
    "\n",
    "    print(f\"RMSE: {score:n} / RATIO: {ratio:.4}%\")\n",
    "    print(f\"best_params: {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.3 SupportVectorRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 8.82 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if config[\"modeling\"][\"svr\"]:\n",
    "\n",
    "    model = SVR()\n",
    "\n",
    "    grid_params = [\n",
    "        {\n",
    "            \"model__kernel\": [\"rbf\"],\n",
    "            \"model__degree\": [3],\n",
    "            \"model__gamma\": [\"scale\"]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    score, ratio, gs, pipeline = evaluate(model, grid_params)\n",
    "\n",
    "    print(f\"RMSE: {score:n} / RATIO: {ratio:.4}%\")\n",
    "    print(f\"best_params: {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.4 DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 7.63 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if config[\"modeling\"][\"tree\"]:\n",
    "\n",
    "    model = DecisionTreeRegressor()\n",
    "\n",
    "    grid_params = [\n",
    "        {\n",
    "            \"model__random_state\": [1],\n",
    "            \"model__max_depth\": [2, 3, 4],\n",
    "            \"model__min_samples_leaf\": range(1, 11, 1),\n",
    "            \"model__criterion\": [\"mse\"]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    score, ratio, gs, pipeline = evaluate(model, grid_params)\n",
    "\n",
    "    print(f\"RMSE: {score:n} / RATIO: {ratio:.4}%\")\n",
    "    print(f\"best_params: {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.5 RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 8.34 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if config[\"modeling\"][\"forest\"]:\n",
    "\n",
    "    model = RandomForestRegressor()\n",
    "\n",
    "    grid_params = [\n",
    "        {\n",
    "            \"model__random_state\": [1],\n",
    "            \"model__n_estimators\": [25],\n",
    "            \"model__min_samples_leaf\": [1],\n",
    "            \"model__criterion\": [\"mse\"]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    score, ratio, gs, pipeline = evaluate(model, grid_params)\n",
    "\n",
    "    print(f\"RMSE: {score:n} / RATIO: {ratio:.4}%\")\n",
    "    print(f\"best_params: {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.6 XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1394,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 199, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true,\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 335, in mean_squared_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 89, in _check_reg_targets\n",
      "    y_true = check_array(y_true, ensure_2d=False, dtype=dtype)\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 199, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true,\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 335, in mean_squared_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 89, in _check_reg_targets\n",
      "    y_true = check_array(y_true, ensure_2d=False, dtype=dtype)\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 199, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true,\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 335, in mean_squared_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 89, in _check_reg_targets\n",
      "    y_true = check_array(y_true, ensure_2d=False, dtype=dtype)\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 199, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true,\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 335, in mean_squared_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 89, in _check_reg_targets\n",
      "    y_true = check_array(y_true, ensure_2d=False, dtype=dtype)\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 199, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true,\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 335, in mean_squared_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 89, in _check_reg_targets\n",
      "    y_true = check_array(y_true, ensure_2d=False, dtype=dtype)\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the test scores are non-finite: [nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_26255/1063314392.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, grid_params, scoring)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;31m# callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultimetric_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mScore\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mapplied\u001b[0m \u001b[0mto\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0mof\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0mon\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \"\"\"\n\u001b[0;32m--> 199\u001b[0;31m         return self._score(partial(_cached_call, None), estimator, X, y_true,\n\u001b[0m\u001b[1;32m    200\u001b[0m                            sample_weight=sample_weight)\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    240\u001b[0m                                                  **self._kwargs)\n\u001b[1;32m    241\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[0m\u001b[1;32m    243\u001b[0m                                                  **self._kwargs)\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;36m0.825\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \"\"\"\n\u001b[0;32m--> 335\u001b[0;31m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[1;32m    336\u001b[0m         y_true, y_pred, multioutput)\n\u001b[1;32m    337\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \"\"\"\n\u001b[1;32m     88\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    721\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if config[\"modeling\"][\"xgboost\"]:\n",
    "\n",
    "    model = XGBRegressor()\n",
    "\n",
    "    grid_params = [\n",
    "        {\n",
    "            \"model__random_state\": [1],\n",
    "            \"model__max_depth\": [3],\n",
    "            \"model__n_estimators\": [100],\n",
    "            \"model__learning_rate\": [0.1],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    score, ratio, gs, pipeline = evaluate(model, grid_params, scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "    print(f\"RMSE: {-score:.4}\")\n",
    "    print(f\"Target mean value: {y_test.mean():.4}\")\n",
    "    print(f\"Ratio: {ratio:.4}%\")\n",
    "    print(f\"best_params: {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With mass-removing\n",
    "\n",
    "RMSE: 0.144  \n",
    "Target mean value: 0.5656  \n",
    "Ratio: 25.46%  \n",
    "best_params: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 100, 'model__random_state': 1}  \n",
    "CPU times: user 21.9 s, sys: 540 ms, total: 22.4 s  \n",
    "Wall time: 2.28 s  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 5 Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2016 dataset is used without any modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE: -1.95016e+06 / RATIO: 34.2%  \n",
    "best_params: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 100, 'model__random_state': 1}  \n",
    "CPU times: user 1min 41s, sys: 2.59 s, total: 1min 44s  \n",
    "Wall time: 10.1 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 5.2 Feature conversion: TaxParcelIdentificationNumber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature 'TaxParcelIdentificationNumber' has been converted from 'object' type to 'float64'\n",
    "We can see that this convertion has a huge negative impact on the accuracy of the model. This is because the feature contain value that are much bigger than the others feature's values, and so, take a big importance in the training.\n",
    "preparation:4.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE: -5.31182e+06 / RATIO: 93.16%  \n",
    "best_params: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 100, 'model__random_state': 1}  \n",
    "CPU times: user 1min 18s, sys: 1.75 s, total: 1min 19s  \n",
    "Wall time: 7.63 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 5.3 Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now scale all the numerical values from 0 to 1. It lead to let the model process 'equally' in weight all the numericals features. We can see a slight improvement compare to the initial error ratio.  \n",
    "preparation:4.3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE: -0.0021134 / RATIO: 32.39%  \n",
    "best_params: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 100, 'model__random_state': 1}  \n",
    "CPU times: user 1min 27s, sys: 1.94 s, total: 1min 29s  \n",
    "Wall time: 8.66 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 5.4 Categoricals features inconsistencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the categoricals features has been stripped an lowerred (removal of leading an tailing spaces and lower all the content).  \n",
    "It appears that no improvement has been done by this process. Most probably due to no or little amount of inconsistencies like several words almost identical but with first letter in uppercase, leading the model to think this is two different values.  \n",
    "preparation:4.2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE: -0.0021134 / RATIO: 32.39%  \n",
    "best_params: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 100, 'model__random_state': 1}  \n",
    "CPU times: user 1min 27s, sys: 2.04 s, total: 1min 29s  \n",
    "Wall time: 8.75 s  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 5.5 Outliers removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that few entries have a lot of value that are outliers. So few that it's acceptable to remove them.  \n",
    "preparation:4.3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE: -0.00144008 / RATIO: 24.59%  \n",
    "best_params: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 100, 'model__random_state': 1}  \n",
    "CPU times: user 1min 29s, sys: 1.97 s, total: 1min 31s  \n",
    "Wall time: 8.87 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 5. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "preparation:..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 6 ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transformer la cible avec log  \n",
    "analyser les résultats des modèles (xgboost): quel sont les points faibles ? quelles sont les features les plus parlantes ? ---> feature engineering\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "586ad1ed5c97141e2437e681efbf1ec0adcd17d830cf5af2ca3d2819e743e158"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
