{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1519,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"feature_eng\": {\n",
    "\n",
    "    },\n",
    "    \"modeling\": {\n",
    "        \"dummy\": False,\n",
    "        \"linear_reg\": False,\n",
    "        \"svr\": False,\n",
    "        \"tree\": False,\n",
    "        \"forest\": False,\n",
    "        \"xgboost\": True\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 1 Dependency import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1520,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import set_config\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1521,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, grid_params, scoring=\"neg_root_mean_squared_error\"):\n",
    "    set_config(display=\"diagram\")\n",
    "    # set_config(display=\"text\")\n",
    "\n",
    "    num_pipe = Pipeline(steps=[\n",
    "        (\"simple_imputer\", SimpleImputer(strategy=\"mean\"))\n",
    "    ])\n",
    "\n",
    "    cat_less_unique_pipe = Pipeline(steps=[\n",
    "        (\"simple_imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    cat_lot_unique_pipe = Pipeline(steps=[\n",
    "        (\"simple_imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num_pipe\", num_pipe, numerical_cols),\n",
    "        (\"cat_less_unique_pipe\", cat_less_unique_pipe, categorical_cols_less_unique),\n",
    "        (\"cat_lot_unique_pipe\", cat_lot_unique_pipe, categorical_cols_lot_unique)\n",
    "    ])\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        (\"transforms\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    gs = GridSearchCV(pipeline, grid_params, scoring=scoring).fit(X_train, y_train)\n",
    "\n",
    "    score = gs.score(X_test, y_test)\n",
    "    ratio = (score * 100) / y_test.mean()\n",
    "    ratio = np.abs(ratio)\n",
    "\n",
    "    return score, ratio, gs, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1522,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mi_scores(X, y, discrete_features):\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1523,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores)\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(\"Mutual Information Scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 2 Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1524,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/data-cleaned.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1525,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target = \"GHGEmissionsIntensity(kgCO2e/ft2)\"\n",
    "target = \"SiteEnergyUse(kBtu)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1526,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[target]\n",
    "X = data.drop(columns=[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1527,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test_full, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1528,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols_less_unique = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and X_train_full[cname].dtype == \"object\"]\n",
    "categorical_cols_lot_unique = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() >= 10 and X_train_full[cname].dtype == \"object\"]\n",
    "numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1529,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cols = categorical_cols_lot_unique + categorical_cols_less_unique + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_test = X_test_full[my_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    661.000000\n",
       "mean       0.565636\n",
       "std        1.035041\n",
       "min        0.000000\n",
       "25%        0.113502\n",
       "50%        0.221829\n",
       "75%        0.582242\n",
       "max       13.118825\n",
       "Name: SiteEnergyUse(kBtu), dtype: float64"
      ]
     },
     "execution_count": 1530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 3 Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1531,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_MI = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1532,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_MI[\"DefaultData\"] = X_MI[\"DefaultData\"].astype(\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1533,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_MI_NUM = X_MI.select_dtypes([\"int64\", \"float64\"]).columns\n",
    "X_MI_CAT = X_MI.select_dtypes([\"object\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1534,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_features = X_MI.dtypes == object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1535,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impt_num = SimpleImputer(strategy=\"mean\")\n",
    "# X_MI[X_MI_NUM] = pd.DataFrame(impt_num.fit_transform(X_MI[X_MI_NUM]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impt_cat = SimpleImputer(strategy=\"most_frequent\")\n",
    "# X_MI[X_MI_CAT] = pd.DataFrame(impt_cat.fit_transform(X_MI[X_MI_CAT]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1537,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in X_MI_CAT:\n",
    "#     X_MI[col], _ = X_MI[col].factorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1538,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = make_mi_scores(X_MI, y, discrete_features).sort_values(ascending=False)\n",
    "# scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1539,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_mi_scores(scores):\n",
    "#     plt.figure(dpi=100, figsize=(8, 5))\n",
    "#     scores = scores.sort_values(ascending=True)\n",
    "#     width = np.arange(len(scores))\n",
    "#     ticks = list(scores.index)\n",
    "#     plt.barh(width, scores)\n",
    "#     plt.yticks(width, ticks)\n",
    "#     plt.title(\"Mutual Information Scores\")\n",
    "\n",
    "# plot_mi_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 4 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.1 DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 8.11 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if config[\"modeling\"][\"dummy\"]:\n",
    "\n",
    "    model = DummyRegressor()\n",
    "\n",
    "    grid_params = [\n",
    "        {\n",
    "            \"model__strategy\": [\"mean\", \"median\"]\n",
    "        },\n",
    "        {\n",
    "            \"model__strategy\": [\"quantile\"],\n",
    "            \"model__quantile\": np.arange(0, 1.1, 0.1),\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    score, ratio, gs, pipeline = evaluate(model, grid_params)\n",
    "\n",
    "    print(f\"RMSE: {score:n} / RATIO: {ratio:.4}%\")\n",
    "    print(f\"best_params: {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.2 LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
      "Wall time: 7.63 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if config[\"modeling\"][\"linear_reg\"]:\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "    grid_params = [\n",
    "        {\n",
    "            \"model__fit_intercept\": [True]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    score, ratio, gs, pipeline = evaluate(model, grid_params)\n",
    "\n",
    "    print(f\"RMSE: {score:n} / RATIO: {ratio:.4}%\")\n",
    "    print(f\"best_params: {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.3 SupportVectorRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 8.58 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if config[\"modeling\"][\"svr\"]:\n",
    "\n",
    "    model = SVR()\n",
    "\n",
    "    grid_params = [\n",
    "        {\n",
    "            \"model__kernel\": [\"rbf\"],\n",
    "            \"model__degree\": [3],\n",
    "            \"model__gamma\": [\"scale\"]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    score, ratio, gs, pipeline = evaluate(model, grid_params)\n",
    "\n",
    "    print(f\"RMSE: {score:n} / RATIO: {ratio:.4}%\")\n",
    "    print(f\"best_params: {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.4 DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 µs, sys: 0 ns, total: 9 µs\n",
      "Wall time: 14.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if config[\"modeling\"][\"tree\"]:\n",
    "\n",
    "    model = DecisionTreeRegressor()\n",
    "\n",
    "    grid_params = [\n",
    "        {\n",
    "            \"model__random_state\": [1],\n",
    "            \"model__max_depth\": [2, 3, 4],\n",
    "            \"model__min_samples_leaf\": range(1, 11, 1),\n",
    "            \"model__criterion\": [\"mse\"]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    score, ratio, gs, pipeline = evaluate(model, grid_params)\n",
    "\n",
    "    print(f\"RMSE: {score:n} / RATIO: {ratio:.4}%\")\n",
    "    print(f\"best_params: {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.5 RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 8.82 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if config[\"modeling\"][\"forest\"]:\n",
    "\n",
    "    model = RandomForestRegressor()\n",
    "\n",
    "    grid_params = [\n",
    "        {\n",
    "            \"model__random_state\": [1],\n",
    "            \"model__n_estimators\": [25],\n",
    "            \"model__min_samples_leaf\": [1],\n",
    "            \"model__criterion\": [\"mse\"]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    score, ratio, gs, pipeline = evaluate(model, grid_params)\n",
    "\n",
    "    print(f\"RMSE: {score:n} / RATIO: {ratio:.4}%\")\n",
    "    print(f\"best_params: {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.6 XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.1439\n",
      "Target mean value: 0.5656\n",
      "Ratio: 25.43%\n",
      "best_params: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 100, 'model__random_state': 1}\n",
      "CPU times: user 1min 24s, sys: 1.94 s, total: 1min 26s\n",
      "Wall time: 8.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if config[\"modeling\"][\"xgboost\"]:\n",
    "\n",
    "    model = XGBRegressor()\n",
    "\n",
    "    grid_params = [\n",
    "        {\n",
    "            \"model__random_state\": [1],\n",
    "            \"model__max_depth\": [3],\n",
    "            \"model__n_estimators\": [100],\n",
    "            \"model__learning_rate\": [0.1],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    score, ratio, gs, pipeline = evaluate(model, grid_params, scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "    print(f\"RMSE: {-score:.4}\")\n",
    "    print(f\"Target mean value: {y_test.mean():.4}\")\n",
    "    print(f\"Ratio: {ratio:.4}%\")\n",
    "    print(f\"best_params: {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1546,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_config(display=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06871989, 0.        , 0.00059661, ..., 0.        , 0.        ,\n",
       "       0.        ], dtype=float32)"
      ]
     },
     "execution_count": 1547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi = gs.best_estimator_.named_steps[\"model\"].feature_importances_\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrimaryPropertyType 6.87\n",
      "PropertyName 0.0\n",
      "Address 0.06\n",
      "Neighborhood 0.09\n",
      "ListOfAllPropertyUseTypes 0.0\n",
      "LargestPropertyUseType 0.06\n",
      "SecondLargestPropertyUseType 0.02\n",
      "ThirdLargestPropertyUseType 0.02\n",
      "BuildingType 8.16\n",
      "ComplianceStatus 14.58\n",
      "Unnamed: 0 0.06\n",
      "OSEBuildingID 0.0\n",
      "ZipCode 0.03\n",
      "TaxParcelIdentificationNumber 0.0\n",
      "CouncilDistrictCode 0.17\n",
      "Latitude 0.0\n",
      "Longitude 0.0\n",
      "YearBuilt 0.04\n",
      "NumberofBuildings 0.03\n",
      "NumberofFloors 0.02\n",
      "PropertyGFATotal 52.49\n",
      "PropertyGFAParking 0.23\n",
      "PropertyGFABuilding(s) 16.84\n",
      "LargestPropertyUseTypeGFA 0.1\n",
      "SecondLargestPropertyUseTypeGFA 0.0\n",
      "ThirdLargestPropertyUseTypeGFA 0.0\n",
      "ENERGYSTARScore 0.0\n",
      "SiteEUI(kBtu/sf) 0.0\n",
      "SourceEUI(kBtu/sf) 0.0\n",
      "SteamUse(kBtu) 0.0\n",
      "Electricity(kWh) 0.0\n",
      "NaturalGas(kBtu) 0.0\n",
      "TotalGHGEmissions 0.0\n",
      "GHGEmissionsIntensity 0.0\n"
     ]
    }
   ],
   "source": [
    "hd = list(X_train.columns)\n",
    "for i, f in zip(hd, fi):\n",
    "     print(i,round(f*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1548,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "# d_test = xgboost.DMatrix(X_test, label=y_test)\n",
    "\n",
    "\n",
    "\n",
    "# params = {\n",
    "#     \"eta\": 0.01,\n",
    "#     \"objective\": \"binary:logistic\",\n",
    "#     \"subsample\": 0.5,\n",
    "#     \"base_score\": np.mean(y_train),\n",
    "#     \"eval_metric\": \"logloss\"\n",
    "# }\n",
    "\n",
    "# model = xgboost.train(params, d_train, 5000, evals = [(d_test, \"test\")], verbose_eval=100, early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 5 Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2016 dataset is used without any modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE: -1.95016e+06 / RATIO: 34.2%  \n",
    "best_params: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 100, 'model__random_state': 1}  \n",
    "CPU times: user 1min 41s, sys: 2.59 s, total: 1min 44s  \n",
    "Wall time: 10.1 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 5.2 Feature conversion: TaxParcelIdentificationNumber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature 'TaxParcelIdentificationNumber' has been converted from 'object' type to 'float64'\n",
    "We can see that this convertion has a huge negative impact on the accuracy of the model. This is because the feature contain value that are much bigger than the others feature's values, and so, take a big importance in the training.\n",
    "preparation:4.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE: -5.31182e+06 / RATIO: 93.16%  \n",
    "best_params: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 100, 'model__random_state': 1}  \n",
    "CPU times: user 1min 18s, sys: 1.75 s, total: 1min 19s  \n",
    "Wall time: 7.63 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 5.3 Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now scale all the numerical values from 0 to 1. It lead to let the model process 'equally' in weight all the numericals features. We can see a slight improvement compare to the initial error ratio.  \n",
    "preparation:4.3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE: -0.0021134 / RATIO: 32.39%  \n",
    "best_params: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 100, 'model__random_state': 1}  \n",
    "CPU times: user 1min 27s, sys: 1.94 s, total: 1min 29s  \n",
    "Wall time: 8.66 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 5.4 Categoricals features inconsistencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the categoricals features has been stripped an lowerred (removal of leading an tailing spaces and lower all the content).  \n",
    "It appears that no improvement has been done by this process. Most probably due to no or little amount of inconsistencies like several words almost identical but with first letter in uppercase, leading the model to think this is two different values.  \n",
    "preparation:4.2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE: -0.0021134 / RATIO: 32.39%  \n",
    "best_params: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 100, 'model__random_state': 1}  \n",
    "CPU times: user 1min 27s, sys: 2.04 s, total: 1min 29s  \n",
    "Wall time: 8.75 s  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 5.5 Outliers removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that few entries have a lot of value that are outliers. So few that it's acceptable to remove them.  \n",
    "preparation:4.3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE: -0.00144008 / RATIO: 24.59%  \n",
    "best_params: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 100, 'model__random_state': 1}  \n",
    "CPU times: user 1min 29s, sys: 1.97 s, total: 1min 31s  \n",
    "Wall time: 8.87 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 5. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "preparation:..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 6 ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transformer la cible avec log -> cela donne des résultats aberrants  \n",
    "analyser les résultats des modèles (xgboost): quel sont les points faibles ? quelles sont les features les plus parlantes ? ---> feature engineering\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "586ad1ed5c97141e2437e681efbf1ec0adcd17d830cf5af2ca3d2819e743e158"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
