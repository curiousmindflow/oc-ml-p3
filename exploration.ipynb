{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"modeling\": {\n",
    "        \"dummy\": False,\n",
    "        \"linear_reg\": False,\n",
    "        \"svr\": False,\n",
    "        \"tree\": False,\n",
    "        \"forest\": False,\n",
    "        \"xgboost\": True\n",
    "    },\n",
    "    \"explain\": {\n",
    "        \"setup\": True,\n",
    "        \"bar\": True,\n",
    "        \"force\": False,\n",
    "        \"waterfall\": False,\n",
    "        \"summary\": False,\n",
    "        \"dependence\": False\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 1 Dependency import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import set_config\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "# plt.style.use([\"dark_background\"])\n",
    "plt.style.use([\"default\"])\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical_features_name(dataset, split_by_unique_count=True, split_count=10):\n",
    "    features_name = dataset.select_dtypes([\"object\", \"bool\"]).columns\n",
    "    if split_by_unique_count:\n",
    "        less_uniques = [feature_name for feature_name in features_name if dataset[feature_name].nunique() <= split_count]\n",
    "        lot_uniques = features_name.difference(less_uniques).tolist()\n",
    "        return (less_uniques, lot_uniques)\n",
    "    else:\n",
    "        return features_name.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numerical_features_name(dataset):\n",
    "    features_name = dataset.select_dtypes([\"int64\", \"float64\"]).columns.values.tolist()\n",
    "    return features_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationResult():\n",
    "    def __init__(self, gridsearch, target, X_train, y_train, X_test, y_test, num_cols, cat_less_unique_cols, cat_lot_unique_cols):\n",
    "        self.__gs = gridsearch\n",
    "        self.__X_train = X_train\n",
    "        self.__y_train = y_train\n",
    "        self.__X_test = X_test\n",
    "        self.__y_test = y_test\n",
    "        self.__target = target\n",
    "        self.__score = self.__gs.score(self.__X_test, self.__y_test)\n",
    "        self.__ratio = np.abs((self.__score * 100) / self.__y_test.mean())\n",
    "        self.__num_cols = num_cols\n",
    "        self.__cat_less_unique_cols = cat_less_unique_cols\n",
    "        self.__cat_lot_unique_cols = cat_lot_unique_cols\n",
    "        self.__cat_less_unique_cols_preproc = self.__gs.best_estimator_[\"transforms\"].transformers_[1][1][\"one_hot_encoder\"].get_feature_names_out(self.__cat_less_unique_cols).tolist()\n",
    "\n",
    "        self.best_model = self.__gs.best_estimator_.named_steps[\"model\"]\n",
    "        self.feature_names = self.__num_cols + self.__cat_less_unique_cols_preproc + self.__cat_lot_unique_cols\n",
    "\n",
    "        self.X_train_transform = pd.DataFrame(data=self.__gs.best_estimator_.named_steps[\"transforms\"].transform(self.__X_train), columns=self.feature_names)\n",
    "        self.X_test_transform = pd.DataFrame(data=self.__gs.best_estimator_.named_steps[\"transforms\"].transform(self.__X_test), columns=self.feature_names)\n",
    "\n",
    "    def print_metrics(self):\n",
    "        print(f\"RMSE: {-self.__score:.4}\")\n",
    "        print(f\"Target mean value: {self.__target.mean():.4}\")\n",
    "        print(f\"Ratio: {self.__ratio:.4}%\")\n",
    "        print(f\"best_params: {self.__gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, grid_params, dataset, target, scoring=\"neg_root_mean_squared_error\"):\n",
    "    set_config(display=\"diagram\") # display=\"text\" -> for textual output\n",
    "\n",
    "    ### DATASET PREPARATION ###\n",
    "\n",
    "    y = dataset[target].copy()\n",
    "    X = dataset.drop(columns=[target]).copy()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=1)\n",
    "\n",
    "    categorical_cols_less_unique, categorical_cols_lot_unique = get_categorical_features_name(X_train)\n",
    "    numerical_cols = get_numerical_features_name(X_train)\n",
    "\n",
    "    ### PIPELINE CONSTRUCTION ###\n",
    "\n",
    "    num_pipe = Pipeline(steps=[\n",
    "        (\"simple_imputer\", SimpleImputer(strategy=\"mean\"))\n",
    "    ])\n",
    "\n",
    "    cat_less_unique_pipe = Pipeline(steps=[\n",
    "        (\"simple_imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    cat_lot_unique_pipe = Pipeline(steps=[\n",
    "        (\"simple_imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"ordinal_encoder\", OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num_pipe\", num_pipe, numerical_cols),\n",
    "        (\"cat_less_unique_pipe\", cat_less_unique_pipe, categorical_cols_less_unique),\n",
    "        (\"cat_lot_unique_pipe\", cat_lot_unique_pipe, categorical_cols_lot_unique)\n",
    "    ])\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        (\"transforms\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    ### GRIDSEARCH DECLARATION AND FITTING ###\n",
    "\n",
    "    gs = GridSearchCV(pipeline, grid_params, scoring=scoring, refit=True)\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    return EvaluationResult(gs, y, X_train, y_train, X_test, y_test, numerical_cols, categorical_cols_less_unique, categorical_cols_lot_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mi_scores(X, y, discrete_features):\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores)\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(\"Mutual Information Scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 2 Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/data-cleaned.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_1 = \"SiteEnergyUse(kBtu)\"\n",
    "target_2 = \"GHGEmissionsIntensity(kgCO2e/ft2)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = data[target]\n",
    "# X = data.drop(columns=[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_full, X_test_full, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_cols_less_unique = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and X_train_full[cname].dtype == \"object\"]\n",
    "# categorical_cols_lot_unique = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() >= 10 and X_train_full[cname].dtype == \"object\"]\n",
    "# numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_cols = categorical_cols_lot_unique + categorical_cols_less_unique + numerical_cols\n",
    "# X_train = X_train_full[my_cols].copy()\n",
    "# X_test = X_test_full[my_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 3 Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_per_floor = \"Electricity(kWh/fl)\"\n",
    "data[elec_per_floor] = (data[\"Electricity(kWh)\"] / data[\"NumberofFloors\"])\n",
    "data[elec_per_floor].replace(np.inf, 0, inplace=True)\n",
    "data[elec_per_floor].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 4 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"modeling\"][\"dummy\"]:\n",
    "\n",
    "    model = DummyRegressor()\n",
    "\n",
    "    grid_params = [\n",
    "        {\n",
    "            \"model__strategy\": [\"mean\", \"median\"]\n",
    "        },\n",
    "        {\n",
    "            \"model__strategy\": [\"quantile\"],\n",
    "            \"model__quantile\": np.arange(0, 1.1, 0.1),\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    eval_result = evaluate(model, grid_params, data, target_1)\n",
    "\n",
    "    eval_result.print_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.2 LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"modeling\"][\"linear_reg\"]:\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "    grid_params = [\n",
    "        {\n",
    "            \"model__fit_intercept\": [True]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    eval_result = evaluate(model, grid_params, data, target_1)\n",
    "\n",
    "    eval_result.print_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.3 SupportVectorRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"modeling\"][\"svr\"]:\n",
    "\n",
    "    model = SVR()\n",
    "\n",
    "    grid_params = [\n",
    "        {\n",
    "            \"model__kernel\": [\"rbf\"],\n",
    "            \"model__degree\": [3],\n",
    "            \"model__gamma\": [\"scale\"]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    eval_result = evaluate(model, grid_params, data, target_1)\n",
    "\n",
    "    eval_result.print_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.4 DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"modeling\"][\"tree\"]:\n",
    "\n",
    "    model = DecisionTreeRegressor()\n",
    "\n",
    "    grid_params = [\n",
    "        {\n",
    "            \"model__random_state\": [1],\n",
    "            \"model__max_depth\": [2, 3, 4],\n",
    "            \"model__min_samples_leaf\": range(1, 11, 1),\n",
    "            \"model__criterion\": [\"mse\"]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    eval_result = evaluate(model, grid_params, data, target_1)\n",
    "\n",
    "    eval_result.print_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.5 RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"modeling\"][\"forest\"]:\n",
    "\n",
    "    model = RandomForestRegressor()\n",
    "\n",
    "    grid_params = [\n",
    "        {\n",
    "            \"model__random_state\": [1],\n",
    "            \"model__n_estimators\": [25],\n",
    "            \"model__min_samples_leaf\": [1],\n",
    "            \"model__criterion\": [\"mse\"]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    eval_result = evaluate(model, grid_params, data, target_1)\n",
    "\n",
    "    eval_result.print_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.6 XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"modeling\"][\"xgboost\"]:\n",
    "\n",
    "    model = XGBRegressor()\n",
    "\n",
    "    grid_params = [\n",
    "        {\n",
    "            \"model__random_state\": [1],\n",
    "            \"model__max_depth\": [6], # 6, 3 .. 10\n",
    "            \"model__n_estimators\": [100], # 100, 100 .. 1000\n",
    "            \"model__learning_rate\": [0.04], # 0.3, 0.01 .. 0.3\n",
    "            \"model__colsample_bytree\": [1], # 1, 0.5 .. 1\n",
    "            \"model__subsample\": [1], # 1, 0.6 .. 1\n",
    "            \"model__alpha\": [0], # 0\n",
    "            \"model__lambda\": [1], # 1\n",
    "            \"model__gamma\": [0], # 0\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    eval_result = evaluate(model, grid_params, data, target_1)\n",
    "\n",
    "    eval_result.print_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE: 0.1126  \n",
    "Target mean value: 0.621  \n",
    "Ratio: 19.9%  \n",
    "best_params: {'model__alpha': 0, 'model__colsample_bytree': 1, 'model__gamma': 0, 'model__lambda': 1, 'model__learning_rate': 0.04, 'model__max_depth': 6, 'model__n_estimators': 100, 'model__random_state': 1, 'model__subsample': 1}  \n",
    "CPU times: user 2min 56s, sys: 3.86 s, total: 2min 59s  \n",
    "Wall time: 16.4 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE: 0.1177  \n",
    "Target mean value: 0.621  \n",
    "Ratio: 20.81%  \n",
    "best_params: {'model__alpha': 0, 'model__colsample_bytree': 1, 'model__gamma': 0, 'model__lambda': 1, 'model__learning_rate': 0.05, 'model__max_depth': 6, 'model__n_estimators': 100, 'model__random_state': 1, 'model__subsample': 1}  \n",
    "CPU times: user 2min 20s, sys: 4.11 s, total: 2min 24s  \n",
    "Wall time: 13.1 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE: 0.1331  \n",
    "Target mean value: 0.621  \n",
    "Ratio: 23.53%  \n",
    "best_params: {'model__learning_rate': 0.1, 'model__max_depth': 6, 'model__n_estimators': 100, 'model__random_state': 1}  \n",
    "CPU times: user 2min 52s, sys: 4.62 s, total: 2min 56s  \n",
    "Wall time: 16.2 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 5 Feature explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Explainer setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"setup\"]:\n",
    "    explainer = shap.TreeExplainer(eval_result.best_model, data=eval_result.X_train_transform)\n",
    "    explainer_bis = explainer(eval_result.X_train_transform)\n",
    "    shap_values = explainer.shap_values(eval_result.X_train_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 5.2 Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"bar\"]:\n",
    "    shap.plots.bar(explainer_bis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"force\"]:\n",
    "    shap.force_plot(explainer.expected_value, shap_values[0,:], eval_result.X_train_transform.iloc[0,:], matplotlib=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"waterfall\"]:\n",
    "    shap.plots.waterfall(explainer_bis[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 5.3 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"summary\"]:\n",
    "    shap.summary_plot(shap_values, eval_result.X_train_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 5.4 Dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"dependence\"]:\n",
    "    shap.dependence_plot(\"Electricity(kWh)\", shap_values, eval_result.X_train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"dependence\"]:\n",
    "    shap.dependence_plot(\"NumberofFloors\", shap_values, eval_result.X_train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"dependence\"]:\n",
    "    shap.dependence_plot(\"SiteEUI(kBtu/sf)\", shap_values, eval_result.X_train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"dependence\"]:\n",
    "    shap.dependence_plot(\"Latitude\", shap_values, eval_result.X_train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"dependence\"]:\n",
    "    shap.dependence_plot(\"Longitude\", shap_values, eval_result.X_train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"dependence\"]:\n",
    "    shap.dependence_plot(\"CouncilDistrictCode\", shap_values, eval_result.X_train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if config[\"explain\"][\"dependence\"]:\n",
    "    shap.dependence_plot(\"YearBuilt\", shap_values, eval_result.X_train_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 6 ..."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "586ad1ed5c97141e2437e681efbf1ec0adcd17d830cf5af2ca3d2819e743e158"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
